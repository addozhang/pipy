---
title: "Concepts"
---

# Stream

Pipy is a proxy that works like a "_stream processor_", which means that it takes in _streams_, processes them, and then spits them out as _streams_ too. But unlike what people usually think _streams_ are, Pipy streams are made of **events** instead of bytes. There are four types of events:

* Data
* MessageStart
* MessageEnd
* StreamEnd

A stream coming along from network is a series of **Data** events, each holding a chunk of bytes received from the incoming TCP connection.

What Pipy does is process the events in the input stream. Some are transformed, some are discarded, and new events could be inserted too. The new events generated while the stream passes through Pipy also include other types of events than **Data**, namely **MessageStart**, **MessageEnd** and **StreamEnd**. These non-data events are used as "_markers_", giving the original raw bytes a higher-level meaning needed by your business logic.

Eventually, all events left in the stream after the processing are sent back over network to the client. At this point, all other events except **Data** are discared.

# Filter and pipeline

A good way to understand how Pipy works is by analogy with [_Unix pipelines_](https://en.wikipedia.org/wiki/Pipeline_(Unix)).

Incoming streams are processed via a chain of **filters** inside of Pipy. Each filter works somewhat like a tiny Unix process that keeps reading from its input (stdin) and writing to its output (stdout), with the output of one filter connected to the input of the next. The only thing different from Unix pipelines is we are handling streams of **events** here, not bytes.

A chain of filters is called a **pipeline**. There are 4 types of pipelines categorized
by their input sources:

## Port pipeline

A **port pipeline** is created when there is an incoming TCP connection. It reads **Data** events from the connection, processes them, and then writes the result back to the client. This resembles the "_request and response_" communication model as in HTTP, where the input to the pipeline is the request and the output from the pipeline is the response. It's safe to consider every incoming connection to Pipy has a _port pipeline_ related to it, handling the communication happening in that connection.

## Timer pipeline

A **timer pipeline** is one that is created periodically and gets a pair of **MessageStart** and **MessageEnd** events as its only input. Whatever it outputs is simply discarded after all the processing in the filters. This type of pipeline can be used to carry out [_cron job_](https://en.wikipedia.org/wiki/Cron)-like tasks.

## Signal pipeline

A **signal pipeline** is created when a signal is sent to the Pipy process. It gets a pair of **MessageStart** and **MessageEnd** events as its only input. Whatever it outputs is simply discarded after all the processing in the filters. This type of pipeline is useful when certain tasks need to be performed when a signal is received.

## Sub-pipeline

A **sub-pipeline** is a pipeline that can be started from other pipelines by using a **joint filter**. The most basic joint filter, among a couple of others, is **link**. It receives events from its predecessor in the main pipeline, sends them to a sub-pipeline for processing, and then pumps down to its succeeding filter in the main pipeline whatever that sub-pipeline outputs.

One way to look at _joint filters_ and _sub-pipelines_ is analogize them to _callers_ and _callees_ in a sub-routine calling process in procedural programming. The input to the joint filter is the sub-routine's parameters, and the output is the return value.

Unlike sub-pipelines, the other types of pipelines, namely **port pipelines**, **timer pipelines** and **singal pipelines**, cannot be "_called_" internally from a joint filter. They can only be started externally by an incoming connection, a timer or a signal. We call these pipelines **root pipelines**.

# Module

A **module** is a PipyJS source file containing scripts that configure a set of **pipeline layouts**.

A **pipeline layout** tells Pipy what filters a pipeline has and in what order. Note that configuring a pipeline layout in a module doesn't create any pipelines at that moment. It only defines what a pipeline looks like when it is actually created at runtime to handle some input, though in some cases when the meaning is obvious, we use the term "_pipeline_" for "_pipeline layout_" just for brevity.

Since "_modules_" and "_files_" have a one-on-one relationship, we use the 2 terms interchangeably.

# Context

A **context** is a set of variables attached to a pipeline, used by scripts to maintain the current state of the pipeline.

Every pipeline uses the same set of variables across a Pipy module. In other words, contexts are of the same "_shape_" among all pipelines in a module, but different modules can have different context shapes. When you start a Pipy module, the first thing is define the _shape_ of the context, meaning what variables it is going to use and their initial values.

Although all pipelines from the same module have exactly the same set of context variables, each pipeline can have its own variable values that are isolated from others, or each pipeline can have its own "_state_", so to speak.

To the scripts of a module, these context variables are used like **global varaibles**, which means that they are always accessible to the scripts from anywhere in the same file.

This might seem odd to a seasoned programmer because "_global variable_" usually means "_globally unique_", you should have only one state of these variables, whereas in Pipy you can have many separate states of them depending on how many pipelines are currently alive. If you are familiar with multi-thread programming concepts, you can correlate this with [_TLS (thread-local storage)_](https://en.wikipedia.org/wiki/Thread-local_storage), where _global variables_ can have different states across different _threads_, or in the case of Pipy, _context variables_ can have different states across different _pipelines_.

We use the terms "_context variable_" and "_global variable_" interchangeably.
